#大树dba日常操作手册

###发布系统 数据库名和表名添加
如果开发或者测试提交工单，没有对应的数据库或者数据库表，需要dba手动向发布系统的相关表当中写入数据库或者表。数据库是172.16.14.253的publish。

* 1 库名添加

```sql
insert into t_datasource_info(datasourcename) values('IDC|basisdata|172.16.100.203|生产')
```

datasourcename字段用|分割，IDC表示数据库是在IDC机房里面的，后面依次是数据库名，vip（如果没有，就是ip），数据库描述。


* 2 表名添加

```sql
insert into t_datasource_table_info(datasourceid,tablename) values(145,'t_project')
```

datasourceid表示数据库在t\_datasource\_info表当中的id字段。如果他们申请的是数据库下的所有数据库表，可以不用添加表名，只有指定需要哪个表的时候才需要添加表名。


###数据库工单自动执行
目前数据库工单分为两类，一类是项目发布的工单，这类工单都需要手动执行。另一类为数据修改工单和只读权限申请工单

* 1 数据修改工单
只会自动处理数据库是IDC并且都是dml的情况。如果出现非IDC的库或者含有ddl，整个工单的所有的语句都不会执行。执行成功和执行失败都会发邮件给工单申请人。具体脚本请查看运维平台当中的dml_execute.py文件。

* 2 只读权限申请工单
只会自动处理IDC和tidb的只读库权限，工单系统上只有个人的权限申请，没有业务系统账号的权限申请。业务系统需要手动处理


###mysql高可用操作指令
mysql采用mha的高可用架构，基本都是一主三从或者一主两从。其中一个从库为延迟库(延迟24个小时)，也是mha的manager节点，并且配置有binlogserver,其余的节点都是node节点。mha的配置文件都在/app/mha目录下

* 1 service mha ssh 检查各节点之间ssh是否畅通
* 2 service mha repl 检查主从是否正常
* 3 service mha status 检查mha manager 节点程序是否正常
* 4 service mha stop 停止mha manager 程序
* 5 service mha start 启动mha manager 程序
* 6 masterha\_master\_switch --master_state=alive	--conf=/app/mha/conf/app1.cnf --new\_master\_host=172.17.100.17 --new\_master\_port=35972 --orig\_master\_is\_new\_slave --interactive=0  
手动切换主从。master_state主库的状态，如果是活着的，设置为alive,如果是死的，设置为dead.orig\_master\_is\_new\_slave 是否把原来的主库设置成新主库的从库。如果不需要可以去掉。执行时需要停止mha主程序。

###ddl执行
使用pt-online-schema-change执行ddl语句。如果表的数据行数大于1000万。需要先通知大数据部门，因为该工具会生成中间表。
 
 
###慢日志清理

```sql
SET GLOBAL slow_query_log = 'OFF';
SET sql_log_bin = 'OFF'; 防止主库执行清理命令时，命令传到从库执行报错
RENAME TABLE slow_log TO slow_log_temp;
DELETE FROM slow_log_temp WHERE start_time < date_add(now(), interval -7 hour);
RENAME TABLE slow_log_temp TO slow_log;
SET GLOBAL slow_query_log = 'ON';
```

如果没有设置sql_log_bin=off，会导致主库的清理命令传送到从库，导致这个报错
Worker 1 failed executing transaction '0b414c22-9bb8-11e8-8c84-d0946655db6d:911479195' at master log bin-log.018223, end_log_pos 7327241; Could not execute Delete_rows event on table mysql.slow_log_temp; Can't find record in 'slow_log_temp', Error_code: 1032; handler error HA_ERR_END_OF_FILE; the event's master log bin-log.018223, end_log_pos 7327241。从库清理时也要设置这个。不然主从切换的时候，由于有这个操作的binlog记录，会导致主从切换失败。


###redis大量key清理
如果只是几个key，可以直接手动删除，如果是手工操作已经很麻烦的，可以使用脚本删除。

先统计脚本统计一共有多少个key

```python
import redis
key_pattern = 'USERCENTER:TOKEN:MAP*'
r = redis.StrictRedis(host = "172.17.100.16",port = 6379)
cursor,data = r.scan(match=key_pattern,count=10000)
i = 0
while cursor != 0:
    print(len(data))
    i = i + len(data)
    cursor, data = r.scan(match=key_pattern,cursor=cursor, count=10000)
print(i)
```
这里需要注意的是，如果本来没有匹配的key的话，那么会一直返回0个数据，并且不会结束scan。
在使用脚本删除

```python
import redis
key_pattern = 'USERCENTER:TOKEN:MAP:*'
r = redis.StrictRedis(host = "172.17.13.202",port = 6379,password = "r-tj725bda9a0bae54:Dashu0701")
cursor,data = r.scan(match=key_pattern,count=1000)

while cursor != 0:
    print(len(data))
    print(cursor)
    if len(data) == 0:
        continue
    if len(data) != 0:
        print(r.delete(*data))
    cursor, data = r.scan(match=key_pattern,cursor=cursor, count=1000)
```
 